{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e962224-1332-4459-bb84-6a26667a955d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üîç üìÉ Pattern matching with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b52c08-02dd-4031-8806-f756cf46bcde",
   "metadata": {},
   "source": [
    "This notebook contains the code presented in the pattern matching with spaCy article on my website [here](https://dhaifbekha.co.uk/articles/pattern-matching-with-spacy).\n",
    "\n",
    "**Warning**: Depending on when you are running this notebook, the code below maybe outdated due to a change in packages version for example. If you experience such issue, please flag it to me ([here](https://dhaifbekha.co.uk/about) or on [Github](https://github.com/Dhaif)) and I will update the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d568e-afb1-49ef-8eef-c29350c87ecb",
   "metadata": {},
   "source": [
    "## Introductionary example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb83c3-0229-47bf-bb02-6157514b61b5",
   "metadata": {},
   "source": [
    "First, an example of rule-based matching using classic regular expression. For this example we will use an sample of Albert Einstein biography available on wikipedia, [here](https://en.wikipedia.org/wiki/Albert_Einstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d77d9eb-0ae0-4736-bd18-40852755e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample of text\n",
    "text = (\n",
    "    \"Early correspondence between Einstein and Mariƒá was discovered and published in 1987 which revealed that the couple had a daughter \"\n",
    "    \"named 'Lieserl', born in early 1902 in Novi Sad where Mariƒá was staying with her parents. \"\n",
    "    \"Mariƒá returned to Switzerland without the child, whose real name and fate are unknown. \"\n",
    "    \"The contents of Einstein's letter in September 1903 suggest that the girl was either given up \"\n",
    "    \"for adoption or died of scarlet fever in infancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4e3a1285-c5fc-41b8-91a3-78e20abc54fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: September 1903\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Find strings matching the pattern of Month followed by the year using the search method\n",
    "# of the Regular Expression operations built-in module.\n",
    "pattern = re.search(\n",
    "    r\"((\\b\\d{1,2}\\D{0,3})?\\b(?:Jan(?:uary)?|Feb(?:ruary)?|Marc(?:h)?|Apr(?:il)?|May|Jun(?:e)?|\"\n",
    "    r\"Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|(Nove|Dec)(?:ember)?)\\D?)(\\d{1,2}(st|nd|rd|th)\"\n",
    "    r\"?)?((\\s*[,.\\-\\/]\\s*)\\D?)?\\s*((19[0-9]\\d|20\\d{2})|\\d{2})*\",\n",
    "    text,\n",
    ")\n",
    "print(f\"Matches: {pattern.group()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a801b0-e6fa-49ae-914c-44757eab3775",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rule-based matching with spaCy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9f6f968e-b62d-4059-9001-826280d4e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load a pre-trained pipeline for the English language\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text with the nlp spaCy pipeline object\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6970bebd-0630-4738-9312-e2fc80ce4048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Early,  Entity label: '',  Part-Of-Speech: ADJ, \n",
      "Token: correspondence,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: between,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: Einstein,  Entity label: ORG,  Part-Of-Speech: PROPN, \n",
      "Token: and,  Entity label: '',  Part-Of-Speech: CCONJ, \n",
      "Token: Mariƒá,  Entity label: GPE,  Part-Of-Speech: PROPN, \n",
      "Token: was,  Entity label: '',  Part-Of-Speech: AUX, \n",
      "Token: discovered,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: and,  Entity label: '',  Part-Of-Speech: CCONJ, \n",
      "Token: published,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: in,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: 1987,  Entity label: DATE,  Part-Of-Speech: NUM, \n",
      "Token: which,  Entity label: '',  Part-Of-Speech: DET, \n",
      "Token: revealed,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: that,  Entity label: '',  Part-Of-Speech: SCONJ, \n",
      "Token: the,  Entity label: '',  Part-Of-Speech: DET, \n",
      "Token: couple,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: had,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: a,  Entity label: '',  Part-Of-Speech: DET, \n",
      "Token: daughter,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: named,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: ',  Entity label: '',  Part-Of-Speech: PUNCT, \n",
      "Token: Lieserl,  Entity label: PERSON,  Part-Of-Speech: PROPN, \n",
      "Token: ',  Entity label: '',  Part-Of-Speech: PUNCT, \n",
      "Token: ,,  Entity label: '',  Part-Of-Speech: PUNCT, \n",
      "Token: born,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: in,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: early,  Entity label: DATE,  Part-Of-Speech: ADJ, \n",
      "Token: 1902,  Entity label: DATE,  Part-Of-Speech: NUM, \n",
      "Token: in,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: Novi,  Entity label: '',  Part-Of-Speech: PROPN, \n",
      "Token: Sad,  Entity label: '',  Part-Of-Speech: PROPN, \n",
      "Token: where,  Entity label: '',  Part-Of-Speech: ADV, \n",
      "Token: Mariƒá,  Entity label: '',  Part-Of-Speech: PROPN, \n",
      "Token: was,  Entity label: '',  Part-Of-Speech: AUX, \n",
      "Token: staying,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: with,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: her,  Entity label: '',  Part-Of-Speech: PRON, \n",
      "Token: parents,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: .,  Entity label: '',  Part-Of-Speech: PUNCT, \n",
      "Token: Mariƒá,  Entity label: ORG,  Part-Of-Speech: PROPN, \n",
      "Token: returned,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: to,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: Switzerland,  Entity label: GPE,  Part-Of-Speech: PROPN, \n",
      "Token: without,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: the,  Entity label: '',  Part-Of-Speech: DET, \n",
      "Token: child,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: ,,  Entity label: '',  Part-Of-Speech: PUNCT, \n",
      "Token: whose,  Entity label: '',  Part-Of-Speech: DET, \n",
      "Token: real,  Entity label: '',  Part-Of-Speech: ADJ, \n",
      "Token: name,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: and,  Entity label: '',  Part-Of-Speech: CCONJ, \n",
      "Token: fate,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: are,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: unknown,  Entity label: '',  Part-Of-Speech: ADJ, \n",
      "Token: .,  Entity label: '',  Part-Of-Speech: PUNCT, \n",
      "Token: The,  Entity label: '',  Part-Of-Speech: DET, \n",
      "Token: contents,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: of,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: Einstein,  Entity label: PERSON,  Part-Of-Speech: PROPN, \n",
      "Token: 's,  Entity label: '',  Part-Of-Speech: PART, \n",
      "Token: letter,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: in,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: September,  Entity label: DATE,  Part-Of-Speech: PROPN, \n",
      "Token: 1903,  Entity label: DATE,  Part-Of-Speech: NUM, \n",
      "Token: suggest,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: that,  Entity label: '',  Part-Of-Speech: SCONJ, \n",
      "Token: the,  Entity label: '',  Part-Of-Speech: DET, \n",
      "Token: girl,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: was,  Entity label: '',  Part-Of-Speech: AUX, \n",
      "Token: either,  Entity label: '',  Part-Of-Speech: CCONJ, \n",
      "Token: given,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: up,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: for,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: adoption,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: or,  Entity label: '',  Part-Of-Speech: CCONJ, \n",
      "Token: died,  Entity label: '',  Part-Of-Speech: VERB, \n",
      "Token: of,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: scarlet,  Entity label: '',  Part-Of-Speech: ADJ, \n",
      "Token: fever,  Entity label: '',  Part-Of-Speech: NOUN, \n",
      "Token: in,  Entity label: '',  Part-Of-Speech: ADP, \n",
      "Token: infancy,  Entity label: '',  Part-Of-Speech: NOUN, \n"
     ]
    }
   ],
   "source": [
    "# Explore for each token it's entity label and Part of Speech tag\n",
    "for token in doc:\n",
    "    print(\n",
    "        f\"Token: {token.text}, \",\n",
    "        f\"Entity label: {token.ent_type_}, \"\n",
    "        if token.ent_type_\n",
    "        else \"Entity label: '', \",\n",
    "        f\"Part-Of-Speech: {token.pos_}, \",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8e8d6-e643-47cc-a002-30a1e070e2f5",
   "metadata": {},
   "source": [
    "### Find all date token: naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a4f6a48a-3f06-4611-a111-a9f2a7f51750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 5\n",
      "Match found for DATE pattern:  1987\n",
      "Match found for DATE pattern:  early\n",
      "Match found for DATE pattern:  1902\n",
      "Match found for DATE pattern:  September\n",
      "Match found for DATE pattern:  1903\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Initialize the matcher with the nlp shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Write a pattern for matching all DATE entity label\n",
    "pattern = [\n",
    "    {\"ENT_TYPE\": \"DATE\"},\n",
    "]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"DATE_PATTERN\", [pattern])\n",
    "# Find token that matches the pattern\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Print the total number of found matches\n",
    "print(\"Total matches found: {}\".format(len(matches)))\n",
    "\n",
    "# Loop over the results!\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found for DATE pattern: \", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138b6a7-c0c2-4fd5-9310-e5c18a858378",
   "metadata": {},
   "source": [
    "### Find all date token: improved approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "43cf2170-9fb7-42ee-be3c-3208c18bff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 5\n",
      "Match found for DATE pattern:  1987\n",
      "Match found for DATE pattern:  early 1902\n",
      "Match found for DATE pattern:  1902\n",
      "Match found for DATE pattern:  September 1903\n",
      "Match found for DATE pattern:  1903\n"
     ]
    }
   ],
   "source": [
    "# Initialize the matcher with the nlp shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Write a better pattern fetching composed token relating to a date\n",
    "pattern = [\n",
    "    {\"POS\": \"ADJ\", \"OP\": \"?\"},\n",
    "    {\"POS\": \"PROPN\", \"OP\": \"?\"},\n",
    "    {\"ENT_TYPE\": \"DATE\", \"POS\": \"NUM\"},\n",
    "]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"DATE_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Print the total number of found matches\n",
    "print(\"Total matches found: {}\".format(len(matches)))\n",
    "\n",
    "# Loop over the results!\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found for DATE pattern: \", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3179ef-5d17-4014-b75a-9eab0604a235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}